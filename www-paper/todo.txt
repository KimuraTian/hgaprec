1. symmetric Gaussian argument -- places equal mass on items with very
   high popularity and items with very low popularity

2. make initialization accurate

3. additional cites?
   Cold-start Active Learning with Robust Matrix Factorization (2014)
   Houlsby NMT, Hernandez-Lobato JMH, and Ghahramani Z
   31st International Conference on Machine Learning (ICML)   (to appear)

   Stochastic Inference for Scalable Probabilistic Modelling of Binary Matrices (2014)
   Hernandez-Lobato JMH, Houlsby NMT, and Ghahramani Z
   31st International Conference on Machine Learning (ICML)   (to appear)

   Probabilistic Matrix Factorization with Non-random Missing Data (2014)
   Hernandez-Lobato JMH, Houlsby NMT, and Ghahramani Z
   31st International Conference on Machine Learning (ICML)   (to appear)

4. merge 1.1 (comparison to Gaussian MF) with second-last para in
   related?

5. discuss ranking-based methods in related work
   BPR, CLiMF, and 
   Kapicioglu et al., Collaborative Ranking for Local Preferences

6. in related work (last para): emphasize that we outperform both
   types of MF (subsampling based, down-weighting based)

7. sec 3, para 2: why do we prefer Poisson distribution over Bernoulli
   and censored Poisson even though we are modeling binary data?
   - (prem) i added text; needs revision

8. add CLiMF and Hu et al. to competing methods
   - Hu et al. data points are being generated

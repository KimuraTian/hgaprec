\section{Related work}
The roots of Poisson factorization come from nonnegative matrix
factorization~\cite{Lee:1999}, where the objective function is
equivalent to a factorized Poisson likelihood.  The original NMF
update equations have been shown to be an expectation-maximization
(EM) algorithm for maximum likelihood estimation of a Poisson model
via data augmentation~\cite{Cemgil:2009}.

Placing a Gamma prior on the user weights results in the GaP
model~\cite{Canny:2004}, which was developed as an alternative text
model to latent Dirichlet allocation
(LDA)~\cite{Blei:2003b,Inouye:2014}. The GaP model is fit using the
expectation-maximization algorithm to obtain point estimates for user
preferences and item attributes. The Probabilistic Factor Model
(PFM)~\cite{Ma:2011} improves upon GaP by placing a Gamma prior on the
item weights as well, and using multiplicative update rules to infer
an approximate maximum a posteriori estimate of the latent factors.
In contrast, as explained below, our model uses a hierarchical prior
structure of Gamma priors on both user and item weights, and Gamma
priors over the rate parameters from which these weights are
drawn. This enables us to accurately model the skew in user activity
and item popularity, which contributes to good predictive
performance. Furthermore, we approximate the full posterior over all
latent factors using a scalable variational inference algorithm.

Independently of GaP and user behavior models, Poisson factorization
has been studied in the context of signal processing for source
separation~\cite{Cemgil:2009,Hoffman:2012} and for the purpose of
detecting community structure in network
data~\cite{Ball:2011,Gopalan:2013}. This research includes variational
approximations to the posterior, though the issues and details around
these data differ significantly from user data we consider and our
derivation below (based on auxiliary variables) is more direct.

When modeling implicit feedback data sets, researchers have proposed
merging factorization techniques with neighborhood
models~\cite{Koren:2008}, weighting techniques to adjust the relative
importance of positive examples~\cite{Hu:2008p9402}, and
sampling-based approaches to create informative negative
examples~\cite{Gantner:2012p9364,Dror:2012a,Paquet:2013p9197}.  In
addition to the difficulty in appropriately weighting or sampling
negative examples, there is a known selection bias in provided ratings
that causes further complications~\cite{Marlin:2009,Marlin:2012}.
Poisson factorization does not require such special adjustments and
scales linearly with the number of observed ratings.

We discuss additional related recommendation methods in
\mysec{eval}, where we compare a variety of applicable methods to
Poisson factorization empirically.

